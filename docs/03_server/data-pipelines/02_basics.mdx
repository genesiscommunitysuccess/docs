---
title: 'Data Pipelines - basics'
sidebar_label: 'Basics'
id: basics
keywords: [server, pipelines, basics]
tags:
  - server
  - pipelines
  - basics
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Set-up

You can configure your data pipelines in a file called _app-name_**-pipelines.kts**. This must be located in your application’s **scripts** directory. 

Once created, you need to add this script to your application’s [processes configuration](/server/data-pipelines/configuring-runtime/).

If you are **not** using the [Genesis Gradle Settings Plugin](/operations/project-structure/settings-plugin/) you need to add the following dependency to your app module:

:::note Only if you are not using the Gradle Settings Plugin
If you are using the [Genesis Gradle Settings Plugin](/operations/project-structure/settings-plugin/), you don't need to do this.
:::

<Tabs defaultValue="gradle" values={[{ label: 'Gradle', value: 'gradle', }, { label: 'Maven', value: 'maven', }]}>
    <TabItem value="gradle">

        ```kotlin
        implementation(genesis("pal-datapipeline"))
        ```

    </TabItem>
    <TabItem value="maven">

        ```xml
        <dependency>
            <groupId>global.genesis</groupId>
            <artifactId>genesis-pal-datapipeline</artifactId>
            <version>$genesisVersion</version>
        </dependency>
        ```

    </TabItem>
</Tabs>

## Pipelines

There are two kinds of pipeline:

- Batch pipeline
- Realtime pipeline

Whether or not a pipeline is batch or realtime is dependent on the source used to configure it.
Each pipeline must have a single source and single sink. In between these stages, you can define any number of operator steps.

### Batch pipeline

A batch pipeline will only run once and must be triggered manually via the use of its execute method. The pipeline can be retrieved from the Pipeline Manager class.

The execute method takes in a map of input parameters, which provide the context to be used throughout the pipeline.

Here is an example of a batch pipeline:

```kotlin
// GPAL Script to define pipeline
val fileStorageSource = fileStorageSource()

pipelines {
    pipeline("TEST_FILE_STORAGE") {
        source(fileStorageSource)
            .transform(StreamOperator<PipelineFile, String> { input -> flow {
                input.collect { pipelineFile ->
                    pipelineFile.content.bufferedReader().use { it.readText() } }
            }
            })
            .sink(fileSink)
    }
}
```

#### Triggering execution

You can trigger the execution of the above example pipeline from anywhere in your codebase, here is an example of triggering inside an `eventHandler`:

```kotlin
val pipelineManager = inject<PipelineManager>()

eventHandler<FileStorageData>(name = "FILE_PIPELINE_START") {
        onCommit { event ->
            val details = event.details

            val pipeline = pipelineManager.getBatchPipeline("TEST_FILE_STORAGE")
            pipeline?.execute(mapOf("FILE_STORAGE_ID" to details.fileStorageId, "FILE_NAME" to details.fileName))
            ack()
        }
    }
```

### Realtime pipeline

A realtime pipeline is started as soon as the process running the script is healthy. It is only stopped once the process has shut down. 

If you need to stop or start the pipeline manually, you can do this using the Pipeline Manager; however, this is not recommended. 

Here is an example of a realtime pipeline:

```kotlin
// GPAL Script to define pipeline
val batchPollSource = dbBatchQuery<Trade> {
    source = "MY_SOURCE"
    index = Trade.ByTimestamp
}

pipelines {
    pipeline("TEST_BATCH_POLL_PIPELINE") {
        source(batchPollSource)
            .sink(testSink)
    }
}
```

