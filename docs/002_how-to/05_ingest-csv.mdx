---
title: 'How to : Consume CSV files'
sidebar_label: 'Consume CSV files'
id: ht-ingest-csv
keywords: [csv, copp clark, integration, ingest, ingress, consume]
tags:
    - csv
    - copp clark
    - integration
    - ingest
    - ingress
    - consume
---


import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


## Using Data Pipeline to ingest data
When you need to take in data from an external source, the first option you should consider is to use the platform's Data Pipeline component.

This enables you to define the data source, transform it to match fields in your tables, then insert or update the data in the specified table. This can be set up to handle streaming data or static files.

A good practical example is to be able to take [Copp Clark](https://coppclark.com/) holiday data that arrives in CSV files.

:::info
You can also use the Data Pipeline component to send out data to external systems. This works the same way in reverse, taking data from tables in your Genesis application and transforming it into the format required by the target system.

Here we are going focus on incoming data in static files.
:::

## Transforming data 
To create a Data Pipeline for ingesting data, you create a -project-name_**data-pipeline.kts** file to define a pipeline that maps data from an external source (database, file) to tables in your application. 

Each Data Pipeline must define three things:

- **source** specifies the location of the incoming data
- **operator** parses the source and maps the data to fields in the application's database; typically, you are looking to transform column headings on the incoming files into the relevant fields in the target table in your database
- **sink** is the destination of the transformed data within your application. This can be a file or a queue, for example. You can use this to further update the data and store it somewhere else - such as a different database or a log

## Examples
To show how to use Data Pipeline to ingest data, we have provided an [example application](https://github.com/genesiscommunitysuccess/howto-csv-ingress/tree/main). This provides different scenarios, based on incoming data in Copp Clark holiday files. 

These start at the most basic case and cover increasing levels of complexity.

Throughout, the code in the application includes detailed comments explaining the steps.

:::tip Download, view and run
The examples are within one complete example application, which includes a front end so that you can run and see the data. 

You can [clone the repo](https://github.com/genesiscommunitysuccess/howto-csv-ingress/tree/main) to see the code - which includes comments at the key points to highlight what is being specified - and run the application.
:::

## Setting up a pipeline in your own app

:::info How to create a similar app
To find out how to create an app similar to our example, go to the [readme file](https://github.com/genesiscommunitysuccess/howto-csv-ingress/tree/main) in the repository for instructions.
:::

When you want to create a Data Pipeline in your own application, there are other things you need to do in addition to creating the pipeline files themselves.

### Processes.xml
Every process in your app must be configured in the application's [**-processes.xml**](/server/configuring-runtime/processes/) file. See the [**howto-csv-ingress-processes.xml**](https://github.com/genesiscommunitysuccess/howto-csv-ingress/blob/main/server/howto-csv-ingress-app/src/main/genesis/cfg/howto-csv-ingress-processes.xml) file for a simple example. 

At minimum, you need to:

- add `genesis-pal-datapipeline` to `<module>`
- add `global.genesis.pipeline` to `<package>`
- add the relevant gpal script (e.g. [**howto-csv-ingress-cc-simple-data-pipeline.kts**](https://github.com/genesiscommunitysuccess/howto-csv-ingress/blob/main/server/howto-csv-ingress-app/src/main/genesis/scripts/howto-csv-ingress-cc-simple-data-pipelines.kts)) to `<script`>

For example:
```jsx
<processes>
  <process name="MYAPP_MANAGER">
    ...
    <module>genesis-pal-datapipeline</module>
    <package>global.genesis.pipeline</package>
    <script>myapp-simple-data-pipelines.kts</script>
    ...
  </process>
</processes>
```

We would then add code into the data pipeline file like this:
```jsx
pipelines {
    pipeline("MY_PIPELINE") {
        source(camelSource { location = getDefaultLocalFileCamelLocation(systemDefinition.get("FolderLocation").get(),"FileName") })
            .map { LOG.info("Triggered MY_PIPELINE"); it}
            .split(csvRawDecoder())
            .map { row ->
                ...
            }
            .sink(dbSink())
            .onCompletion
    }
}
```

### System definition
Every application also has a [main configuration file](/server/configuring-runtime/system-definitions/) called **genesis-system-definition.kts**. 

Check this file and make sure that the application knows where to source the files from.

[comment]: <> (surely we need to be more specific here?)

## Testing

:::info
Go to our [**Testing**](/how-to/ht-prepare-test/) page for details of our testing tools and the dependencies that you need to declare.
:::

To test your auth set-up on your app:

- *Details to follow shortly. Thank you for your patience.*


## Full technical details
You can find full technical details of how to use the Data Pipeline in our [reference documentation](/develop/server-capabilities/integrations/data-pipelines/).


