"use strict";(self.webpackChunk_genesislcap_docs=self.webpackChunk_genesislcap_docs||[]).push([[2300],{20714:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return g},frontMatter:function(){return o},metadata:function(){return d},toc:function(){return c}});var a=n(87462),r=n(63366),s=(n(67294),n(3905)),i=(n(61839),["components"]),o={title:"Data Pipeline - Testing",sidebar_label:"Testing",id:"testing",keywords:["server","integration","data pipeline","testing"],tags:["server","integration","data pipeline","testing"]},l=void 0,d={unversionedId:"server/integration/data-pipeline/testing",id:"version-2022.3/server/integration/data-pipeline/testing",title:"Data Pipeline - Testing",description:"Introduction  | Basics | Advanced | Examples | Configuring runtime | Testing",source:"@site/versioned_docs/version-2022.3/03_server/10_integration/08_data-pipeline/06_testing.md",sourceDirName:"03_server/10_integration/08_data-pipeline",slug:"/server/integration/data-pipeline/testing",permalink:"/server/integration/data-pipeline/testing",draft:!1,tags:[{label:"server",permalink:"/tags/server"},{label:"integration",permalink:"/tags/integration"},{label:"data pipeline",permalink:"/tags/data-pipeline"},{label:"testing",permalink:"/tags/testing"}],version:"2022.3",sidebarPosition:6,frontMatter:{title:"Data Pipeline - Testing",sidebar_label:"Testing",id:"testing",keywords:["server","integration","data pipeline","testing"],tags:["server","integration","data pipeline","testing"]},sidebar:"serverModulesSidebar",previous:{title:"Configuring Runtime",permalink:"/server/integration/data-pipeline/configuring-runtime"},next:{title:"Excel reference",permalink:"/server/integration/excel-to-genesis/excel-reference"}},p={},c=[{value:"Starting source PostgreSQL",id:"starting-source-postgresql",level:2},{value:"Testcontainers",id:"testcontainers",level:3},{value:"Docker image",id:"docker-image",level:3},{value:"Standalone process",id:"standalone-process",level:3}],u={toc:c};function g(e){var t=e.components,n=(0,r.Z)(e,i);return(0,s.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/introduction/"},"Introduction"),"  | ",(0,s.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/basics"},"Basics")," | ",(0,s.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/advanced"},"Advanced")," | ",(0,s.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/examples"},"Examples")," | ",(0,s.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/configuring-runtime"},"Configuring runtime")," | ",(0,s.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/testing"},"Testing")),(0,s.kt)("p",null,"To test a data pipeline you need:"),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"source data e.g. PostgreSQL"),(0,s.kt)("li",{parentName:"ul"},"a data pipeline script"),(0,s.kt)("li",{parentName:"ul"},"a test case class that extends ",(0,s.kt)("inlineCode",{parentName:"li"},"AbstractGenesisTestSupport"))),(0,s.kt)("p",null,"This is an example test case that asserts that six trades are ingested from source PostgreSQL:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-kotlin"},"class DataPipelineTest : AbstractGenesisTestSupport<GenesisSet>(\n    GenesisTestConfig {\n        packageName = \"global.genesis.datapipeline.pal\"\n        genesisHome = \"/genesisHome\"\n        parser = { it }\n        scriptFileName = \"test-data-pipeline.kts\"\n    }\n) {\n\n    override fun createDictionary() = testDictionary()\n\n    companion object {\n\n        private val SOURCE_DATABASE_CONNECTION = DriverManager.getConnection(\"jdbc:postgresql://localhost:5432/?user=postgres&password=docker\")\n\n        @JvmStatic\n        @BeforeClass\n        fun setupSourceTable() {\n            dbExecute(\n                \"\"\"\n                CREATE TYPE source_trades_valid_sides AS ENUM ('buy', 'sell');\n                CREATE TYPE source_trades_valid_states AS ENUM ('new', 'mod', 'canc');\n\n                CREATE TABLE source_trades (\n                    trd_id  VARCHAR ( 12 ) PRIMARY KEY,\n                    inst VARCHAR ( 5 ) NOT NULL,\n                    price DOUBLE PRECISION NOT NULL,\n                    quantity INTEGER NOT NULL,\n                    side VALID_SIDES NOT NULL,\n                    traded_at TIMESTAMP NOT NULL,\n                    trader VARCHAR (30) NOT NULL,\n                    trade_state valid_states NOT NULL,\n                    unsolicited BOOL,\n                    orig_trd_id VARCHAR (12)\n                );\n            \"\"\".trimIndent()\n            )\n        }\n\n        @JvmStatic\n        @AfterClass\n        fun closeConnection() {\n            dbExecute(\"DROP TABLE IF EXISTS source_trades;\")\n            dbExecute(\"DROP TYPE IF EXISTS source_trades_valid_sides;\")\n            dbExecute(\"DROP TYPE IF EXISTS source_trades_valid_states;\")\n            SOURCE_DATABASE_CONNECTION.close()\n        }\n\n        private fun dbExecute(statement: String) {\n            SOURCE_DATABASE_CONNECTION.execute(statement).blockingGet()\n        }\n    }\n\n    @Test\n    fun dataPipelineExecution() {\n        Assume.assumeTrue(DB_LAYER == DbLayers.SQL)\n        dbExecute(\n            \"\"\"\n             INSERT INTO source_trades(trd_id, inst, price, quantity, side, traded_at, trader, trade_state, unsolicited, orig_trd_id)\n             VALUES\n              ('ITS_00000004', 'VOD', 126, 1500, 'sell', '2022-05-25 16:01:01', 'Trader.B', 'new', NULL , NULL),\n              ('ITS_00000005', 'BT', 189.35, 5000, 'buy', '2022-05-25 16:02:02', 'Trader.B', 'new',NULL, NULL),\n              ('ITS_00000006', 'VOD', 127, 2000, 'buy', '2022-05-25 14:03:03', 'Trader.B', 'mod', false, 'ITS_00000001'),\n              ('ITS_00000003', 'BARC', 158, 2000, 'buy', '2022-05-25 15:03:03', 'Trader.B', 'canc', false, ''),\n              ('ITS_00000008', 'BT', 189.56, 1000, 'sell', '2022-05-25 16:03:03', 'Trader.B', 'new', true, 'ITS_00000007'),\n              ('ITS_00000009', 'BARC', 158, 2000, 'buy', '2022-05-25 16:04:04', 'Trader.B', 'canc', false, '');\n            \"\"\".trimIndent()\n        )\n\n        Awaitility.await().atMost(Duration.ofSeconds(5)).until {\n            rxDb.count(\"TRADE\").blockingGet() == 6L\n        }\n\n        val tradeIds: List<String> = runBlocking {\n            entityDb.getBulk<Trade>().toList()\n        }.map { it.tradeId }\n\n        val expectedTradeIds = listOf(\n            \"ITS_00000003-TradeStore\",\n            \"ITS_00000004-TradeStore\",\n            \"ITS_00000005-TradeStore\",\n            \"ITS_00000006-TradeStore\",\n            \"ITS_00000008-TradeStore\",\n            \"ITS_00000009-TradeStore\"\n        )\n\n        assert(tradeIds.containsAll(expectedTradeIds))\n    }\n}\n")),(0,s.kt)("p",null,"And this is the data pipeline configuration that is tested:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-kotlin"},'sources {\n\n    postgres("cdc-test") {\n        hostname = "localhost"\n        port = 5432\n        username = "postgres"\n        password = "docker"\n        databaseName = "postgres"\n\n        table {\n            "public.source_trades" to mapper("incoming_trades", TRADE) {\n                val tradeId = stringValue("trd_id")\n                val instrument = stringValue("inst")\n                val tradedAt = longValue("traded_at")\n                val side = stringValue("side")\n                val tradeState = stringValue("trade_state")\n\n                TRADE {\n                    TRADE_ID {\n                        transform {\n                            "${input.get(tradeId)}-TradeStore"\n                        }\n                    }\n\n                    TRADE_TYPE {\n                        sourceProperty = "side"\n                    }\n\n                    TRADE_DATE {\n                        transform {\n                            DateTime(input.get(tradedAt))\n                        }\n                    }\n\n                    INSTRUMENT_ID {\n                        transform {\n                            "${input.get(instrument)}-RIC"\n                        }\n                    }\n\n                    CURRENCY_ID {\n                        transform {\n                            "GBP"\n                        }\n                    }\n\n                    QUANTITY {\n                        sourceProperty = "quantity"\n                    }\n\n                    PRICE {\n                        sourceProperty = "price"\n                    }\n\n                    RECORD_ID {\n                        transform {\n                            input.get(tradeId).removePrefix("ITS_").toLong()\n                        }\n                    }\n\n                    TIMESTAMP {\n                        transform {\n                            input.get(tradedAt)\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n\n')),(0,s.kt)("h2",{id:"starting-source-postgresql"},"Starting source PostgreSQL"),(0,s.kt)("p",null,"There are various ways to start PostgreSQL as a test dependency. Here is a list of the most common ones:"),(0,s.kt)("h3",{id:"testcontainers"},"Testcontainers"),(0,s.kt)("p",null,"You can start PostgreSQL as a test rule using ",(0,s.kt)("a",{parentName:"p",href:"https://www.testcontainers.org/"},"Testcontainers"),". It has a ",(0,s.kt)("a",{parentName:"p",href:"https://www.testcontainers.org/modules/databases/postgres/"},"Postgres Module")," that has a pre-configured rule to use out of the box. However, it requires additional configuration for the Write Ahead Log (WAL) level, and it has to be set to ",(0,s.kt)("inlineCode",{parentName:"p"},"logical"),". Below is a sample rule configuration:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-kotlin"},'PostgreSQLContainer("postgres:12.6-alpine")\n  .withCommand("postgres", "-c", "fsync=off", "-c", "wal_level=logical")\n')),(0,s.kt)("h3",{id:"docker-image"},"Docker image"),(0,s.kt)("p",null,"You can start PostgreSQL as a Docker image as part of the test set-up or the environment set-up. The requirement for WAL level applies here as well. Below is a sample command to start PostgreSQL image:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-shell"},"docker run -tid -p 5432:5432 -e POSTGRES_PASSWORD=docker -e PGDATA=/tmp postgres:12.6-alpine -c wal_level=logical\n")),(0,s.kt)("h3",{id:"standalone-process"},"Standalone process"),(0,s.kt)("p",null,"You can install and start PostgreSQL during environment set-up."))}g.isMDXComponent=!0}}]);