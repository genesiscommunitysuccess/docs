"use strict";(self.webpackChunk_genesislcap_docs=self.webpackChunk_genesislcap_docs||[]).push([[36665],{78870:function(e,t,n){n.r(t),n.d(t,{assets:function(){return d},contentTitle:function(){return r},default:function(){return g},frontMatter:function(){return s},metadata:function(){return p},toc:function(){return u}});var a=n(87462),i=n(63366),o=(n(67294),n(3905)),l=(n(61839),["components"]),s={title:"Go to the next level - Ingest external data",sidebar_label:"Ingest external data",id:"data-pipeline",keywords:["getting started","quick start","next level","data","pipeline"],tags:["getting started","quick start","next level","data","pipeline"]},r=void 0,p={unversionedId:"getting-started/go-to-the-next-level/data-pipeline",id:"version-2022.3/getting-started/go-to-the-next-level/data-pipeline",title:"Go to the next level - Ingest external data",description:"So far, we have only directed you towards manual data ingestion techniques, using gradle tasks, forms, SendIt, Genesis Console or Postman.",source:"@site/versioned_docs/version-2022.3/01_getting-started/03_go-to-the-next-level/12_data-pipeline.md",sourceDirName:"01_getting-started/03_go-to-the-next-level",slug:"/getting-started/go-to-the-next-level/data-pipeline",permalink:"/getting-started/go-to-the-next-level/data-pipeline",draft:!1,tags:[{label:"getting started",permalink:"/tags/getting-started"},{label:"quick start",permalink:"/tags/quick-start"},{label:"next level",permalink:"/tags/next-level"},{label:"data",permalink:"/tags/data"},{label:"pipeline",permalink:"/tags/pipeline"}],version:"2022.3",sidebarPosition:12,frontMatter:{title:"Go to the next level - Ingest external data",sidebar_label:"Ingest external data",id:"data-pipeline",keywords:["getting started","quick start","next level","data","pipeline"],tags:["getting started","quick start","next level","data","pipeline"]},sidebar:"learningSidebar",previous:{title:"Setting Genesis Evaluator rules",permalink:"/getting-started/go-to-the-next-level/setting-genesis-evaluator-rules"},next:{title:"Create a chart",permalink:"/getting-started/go-to-the-next-level/charts"}},d={},u=[{value:"Section objectives",id:"section-objectives",level:2},{value:"Configure data pipeline",id:"configure-data-pipeline",level:2},{value:"Verify your pipeline is working",id:"verify-your-pipeline-is-working",level:2},{value:"Conclusion",id:"conclusion",level:2}],c={toc:u};function g(e){var t=e.components,s=(0,i.Z)(e,l);return(0,o.kt)("wrapper",(0,a.Z)({},c,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"So far, we have only directed you towards manual data ingestion techniques, using gradle tasks, forms, ",(0,o.kt)("a",{parentName:"p",href:"/operations/commands/server-commands/#sendit-script"},"SendIt"),", Genesis Console or Postman.\nHere, we shall look at how you can continuously ingest data using ",(0,o.kt)("a",{parentName:"p",href:"/server/integration/data-pipeline/introduction/"},"Data Pipelines"),"."),(0,o.kt)("p",null,"Data pipelines enable you to ingest data from an external source. You configure:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"what source or sources you want to ingest"),(0,o.kt)("li",{parentName:"ul"},"how they map to your Genesis application's data model"),(0,o.kt)("li",{parentName:"ul"},"what to do with this mapped data.")),(0,o.kt)("h2",{id:"section-objectives"},"Section objectives"),(0,o.kt)("p",null,"The goal of this section is to:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"define and configure a data pipeline process"),(0,o.kt)("li",{parentName:"ul"},"create a data pipeline script"),(0,o.kt)("li",{parentName:"ul"},"ingest a csv of trades data")),(0,o.kt)("h2",{id:"configure-data-pipeline"},"Configure data pipeline"),(0,o.kt)("p",null,"We will be configuring a local filesystem based data pipeline. This will watch a directory for changes over time and consume files that fit the criteria we configure. In this example, files will be read (line-by-line), be transformed/mapped to our data model and then stored in the Genesis database."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Ingress of files via local file system data pipelines, although a simple way to introduce yourself to data pipelines, is considered bad practice in production. Check the data pipelines docs for more information about file ingestion alternatives such as AWS S3 and FTP and relational database sources.")),(0,o.kt)("p",null,"In order to add a CSV local filesystem data pipeline, firstly, add the dependency ",(0,o.kt)("inlineCode",{parentName:"p"},"genesis-pal-datapipeline")," to your ",(0,o.kt)("strong",{parentName:"p"},"position-app-tutorial-script-config")," module. This ensures that you are able to use the data pipeline functionality within your scripts. Ensure that Gradle imports the new dependency."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'api("global.genesis:genesis-pal-datapipeline")\n')),(0,o.kt)("p",null,"Now we can create a new file ",(0,o.kt)("strong",{parentName:"p"},"positions-app-tutorial-data-pipeline.kts")," with the following csv source configuration:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-kotlin"},'import global.genesis.gen.config.tables.TRADE\nimport global.genesis.gen.config.tables.TRADE.COUNTERPARTY_ID\nimport global.genesis.gen.config.tables.TRADE.ENTERED_BY\nimport global.genesis.gen.config.tables.TRADE.INSTRUMENT_ID\nimport global.genesis.gen.config.tables.TRADE.PRICE\nimport global.genesis.gen.config.tables.TRADE.QUANTITY\nimport global.genesis.gen.config.tables.TRADE.SIDE\nimport global.genesis.gen.config.tables.TRADE.TRADE_DATETIME\nimport global.genesis.gen.config.tables.TRADE.TRADE_STATUS\n\nsources {\n  csv("some-name") {\n    location = "file:/home/positions/run/runtime/fileIngress?fileName=trades.csv"\n\n    mapper("mapper-name", TRADE) {\n      INSTRUMENT_ID {\n        sourceProperty = "instrumentId"\n      }\n      COUNTERPARTY_ID {\n        sourceProperty = "counterpartyId"\n      }\n      QUANTITY {\n        sourceProperty = "amount"\n      }\n      SIDE {\n        sourceProperty = "buySell"\n      }\n      PRICE {\n        sourceProperty = "price"\n      }\n      TRADE_DATETIME {\n        transform {\n          input.get(dateValue("date"))\n        }\n      }\n      ENTERED_BY {\n        sourceProperty = "enteredBy"\n      }\n      TRADE_STATUS {\n        transform {\n          TradeStatus.NEW\n        }\n      }\n    }\n  }\n}\n')),(0,o.kt)("p",null,"In the above script, we define a CSV file source. We configure the location as a local filesystem source with an absolute path to the user account's ",(0,o.kt)("inlineCode",{parentName:"p"},"positions")," ",(0,o.kt)("strong",{parentName:"p"},"run/runtime/fileIngress")," directory. This directory should be created automatically the first time your application is started."),(0,o.kt)("p",null,"The remaining configuration defines a mapper from our CSV to the data model of the ",(0,o.kt)("inlineCode",{parentName:"p"},"TRADE")," table."),(0,o.kt)("p",null,"We follow the data pipeline definition with the usual runtime configuration. Ensure that you add the following config to your ",(0,o.kt)("strong",{parentName:"p"},"-processes.xml")," and ",(0,o.kt)("strong",{parentName:"p"},"-service-definitions.xml")," files:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-xml"},'<process name="POSITIONS_APP_TUTORIAL_DATAPIPELINE">\n    <groupId>POSITIONS_APP_TUTORIAL</groupId>\n    <start>true</start>\n    <options>-Xmx256m -DRedirectStreamsToLog=true -DXSD_VALIDATE=false</options>\n    <module>genesis-pal-datapipeline</module>\n    <package>global.genesis.datapipeline.pal</package>\n    <script>positions-app-tutorial-data-pipeline.kts<\/script>\n    <description>External data ingress pipeline</description>\n    <language>pal</language>\n    <loggingLevel>TRACE,DATADUMP_ON</loggingLevel>\n</process>\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-xml"},'<service host="localhost" name="POSITIONS_APP_TUTORIAL_DATAPIPELINE" port="11006"/>\n')),(0,o.kt)("p",null,"We are now ready to deploy the changes. Run ",(0,o.kt)("inlineCode",{parentName:"p"},"assemble")," and then ",(0,o.kt)("inlineCode",{parentName:"p"},"deploy-genesisproduct-positions-app-tutorial"),"."),(0,o.kt)("h2",{id:"verify-your-pipeline-is-working"},"Verify your pipeline is working"),(0,o.kt)("p",null,"We have now configured a CSV source that listens for changes on the local file system!"),(0,o.kt)("p",null,"You can use the following CSV as an example to test your pipeline. Create a file named ",(0,o.kt)("inlineCode",{parentName:"p"},"trades.csv")," and paste the contents below into a running instance of your Genesis application. This will trigger the pipeline into action. "),(0,o.kt)("p",null,"Each row of the CSV will be parsed, mapped and stored in the database. Your CSV file will disappear when the pipeline has processed the file. You can then use the ",(0,o.kt)("inlineCode",{parentName:"p"},"DbMon")," utility to check your database for changes."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-csv"},"instrumentId,counterpartyId,amount,buySell,price,date,enteredBy\nAPPL,A102,140,B,280,2022-09-06 16:20:20,TraderA\nIBM.B,A421,11,S,120,2022-09-06 12:10:52,TraderB\nMSFT,A102,140,B,280,2022-09-08 16:34:00,TraderB\nAPPL,Z233,100,S,400,2022-09-12 16:20:20,TraderA\n")),(0,o.kt)("h2",{id:"conclusion"},"Conclusion"),(0,o.kt)("p",null,"In this section, we have created a working data pipeline. Given everything is working as expected, ",(0,o.kt)("inlineCode",{parentName:"p"},"DbMon")," will show the following 4 entries in your database."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"DbMon screenshot",src:n(72569).Z,width:"2135",height:"2228"})))}g.isMDXComponent=!0},72569:function(e,t,n){t.Z=n.p+"assets/images/dbmon-datapipeline-da6b72de6c0312e89b7ad7dae127a438.PNG"}}]);